{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d61c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" Natural Language Processing (NLP) is a branch of artificial intelligence that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable machines to read, understand, and derive meaning from human language in a valuable way. It involves several key tasks such as text classification, sentiment analysis, machine translation, and question answering. Before applying these techniques, however, it is important to clean and preprocess the text. This includes steps like converting to lowercase, removing punctuation, eliminating stop words, and stemming or lemmatization. By removing common stop words such as \"the\", \"is\", \"and\", and \"to\", we can reduce noise and focus on the more meaningful parts of the text for analysis.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "import pickle\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Load tokenizer directly from the file\n",
    "with open(r\"C:\\Users\\3 Stars Laptop\\Desktop\\Ghufran\\NLP\\tokenizers\\punkt\\english.pickle\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Use it\n",
    "\n",
    "sentences = tokenizer.tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eca415",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2748966",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt', download_dir=\"C:/nltk_data\")\n",
    "nltk.download('stopwords', download_dir=\"C:/nltk_data\")\n",
    "nltk.download('averaged_perceptron_tagger', download_dir=\"C:/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will find the Pos Tag.\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "for i in range (len(sentences)):\n",
    "    words=word_tokenizer.tokenize(sentences[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    pos_tagg=nltk.pos_tag(words)\n",
    "    print(pos_tagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c562da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"To Learn NLP it is little difficult\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.pos_tag_sents(\"To Learn NLP it is little difficult\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cfb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
